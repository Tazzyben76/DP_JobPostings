{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76ba5810-33b3-4d9d-87a9-e097827c1ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\user\\anaconda3_2025\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: psycopg2-binary in c:\\users\\user\\anaconda3_2025\\lib\\site-packages (2.9.11)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\user\\anaconda3_2025\\lib\\site-packages (3.10.0)\n",
      "Requirement already satisfied: wordcloud in c:\\users\\user\\anaconda3_2025\\lib\\site-packages (1.9.4)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\user\\anaconda3_2025\\lib\\site-packages (from pandas) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\anaconda3_2025\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\anaconda3_2025\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\user\\anaconda3_2025\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\user\\anaconda3_2025\\lib\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\anaconda3_2025\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\user\\anaconda3_2025\\lib\\site-packages (from matplotlib) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\user\\anaconda3_2025\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\anaconda3_2025\\lib\\site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\user\\anaconda3_2025\\lib\\site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\user\\anaconda3_2025\\lib\\site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\anaconda3_2025\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas psycopg2-binary matplotlib wordcloud\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9129e892-aa04-4399-b699-8e2f1d4add07",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "job_analysis.py\n",
    "\n",
    "- Connects to PostgreSQL or reads CSV\n",
    "- Produces:\n",
    "    * Word cloud of top skills/terms\n",
    "    * Top countries by job listings (bar chart)\n",
    "    * Min-Max salary per job_title (CSV)\n",
    "    * Top companies by average salary (bar chart + CSV)\n",
    "    * Salary distribution by country (boxplot)\n",
    "- Output files saved in ./output/\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import re\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "efbda72d-2f66-4d47-b95d-82b0fffb6a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- CONFIG ----------\n",
    "USE_CSV = False                # Set True to load from CSV instead of DB\n",
    "CSV_PATH = \"sample_job_data.csv\"   # used if USE_CSV=True\n",
    "\n",
    "# PostgreSQL config (edit)\n",
    "PG_CONFIG = {\n",
    "#    \"host\": \"localhost\",\n",
    "#    \"port\": 5432,\n",
    "#    \"dbname\": \"testdb\",\n",
    "#    \"user\": \"********\",\n",
    "#    \"password\": \"********\"\n",
    "     \"host\": \"jde08-ip-p2-angbj1976-c47c.c.aivencloud.com\",\n",
    "     \"port\": 15241,\n",
    "     \"dbname\": \"Interim_Project_DB\",\n",
    "     \"user\": \"********\",\n",
    "     \"password\": \"********\"\n",
    "}\n",
    "\n",
    "OUTPUT_DIR = \"./output\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c1bdf5f-6bd2-45a3-afac-fa180738e2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keyword list for skill detection (optional; used to weight common tech terms)\n",
    "SKILL_KEYWORDS = [\n",
    "    \"python\",\"sql\",\"java\",\"scala\",\"spark\",\"hadoop\",\"aws\",\"gcp\",\"google cloud\",\n",
    "    \"azure\",\"kubernetes\", \"docker\",\"airflow\",\"etl\",\"data warehouse\",\"redshift\",\n",
    "    \"snowflake\",\"bigquery\",\"dbt\",\"kafka\",\"nosql\",\"mongodb\",\"cassandra\",\"postgresql\",\n",
    "    \"mysql\",\"pandas\",\"numpy\",    \"tensorflow\",\"pytorch\", \"powerbi\",\"tableau\",\"hive\",\n",
    "    \"flink\",\"beam\",\"linux\",\"bash\", \"s3\",\"git\",\"ci/cd\",\"jenkins\",\"databricks\",\"kubeflow\"\n",
    "]\n",
    "SKILL_KEYWORDS = [k.lower() for k in SKILL_KEYWORDS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0f8b7698-8c03-408d-9f2c-7e8bec3402d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_32652\\886529559.py:22: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_jobs = pd.read_sql(\"SELECT * FROM fact_jobs;\", conn)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_32652\\886529559.py:23: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  dim_companies = pd.read_sql(\"SELECT company_id, company_name, country_code FROM dim_companies;\", conn)\n"
     ]
    }
   ],
   "source": [
    "# ---------- LOAD DATA ----------\n",
    "if USE_CSV:\n",
    "    df_jobs = pd.read_csv(CSV_PATH)\n",
    "    # If company table also provided as CSV, load similarly (optional)\n",
    "    dim_companies = None\n",
    "else:\n",
    "    import psycopg2\n",
    "    import sqlalchemy\n",
    "    from sqlalchemy import create_engine\n",
    "\n",
    "    conn = None\n",
    "    try:\n",
    "        conn = psycopg2.connect(\n",
    "            host=PG_CONFIG[\"host\"],\n",
    "            port=PG_CONFIG[\"port\"],\n",
    "            dbname=PG_CONFIG[\"dbname\"],\n",
    "            user=PG_CONFIG[\"user\"],\n",
    "            password=PG_CONFIG[\"password\"]\n",
    "        )\n",
    "\n",
    "        # Pull fact_jobs and dim_companies in one session (keeps connection open while reading)\n",
    "        df_jobs = pd.read_sql(\"SELECT * FROM fact_jobs;\", conn)\n",
    "        dim_companies = pd.read_sql(\"SELECT company_id, company_name, country_code FROM dim_companies;\", conn)\n",
    "\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"DB read error: {e}\")\n",
    "    finally:\n",
    "        # Close connection after we have loaded the required tables\n",
    "        if conn is not None:\n",
    "            conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "12052c0d-d42a-419a-b682-82f0537a0e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- PREP: standardize column names (safe matching) ----------\n",
    "def find_col(df, names):\n",
    "    for n in names:\n",
    "        if n in df.columns:\n",
    "            return n\n",
    "    # case-insensitive match\n",
    "    cols_lower = {c.lower(): c for c in df.columns}\n",
    "    for n in names:\n",
    "        if n.lower() in cols_lower:\n",
    "            return cols_lower[n.lower()]\n",
    "    return None\n",
    "\n",
    "# ensure job_title, description columns\n",
    "job_title_col = find_col(df_jobs, [\"job_title\", \"title\"])\n",
    "desc_col = find_col(df_jobs, [\"description\", \"job_description\", \"summary\"])\n",
    "\n",
    "# salary columns detection\n",
    "salary_min_col = find_col(df_jobs, [\"salary_min\", \"min_salary\", \"salary_from\", \"salary_low\"])\n",
    "salary_max_col = find_col(df_jobs, [\"salary_max\", \"max_salary\", \"salary_to\", \"salary_high\"])\n",
    "\n",
    "# company_id\n",
    "company_id_col = find_col(df_jobs, [\"company_id\"])\n",
    "\n",
    "# Force salary columns numeric if present\n",
    "if salary_min_col:\n",
    "    df_jobs[salary_min_col] = pd.to_numeric(df_jobs[salary_min_col], errors='coerce')\n",
    "if salary_max_col:\n",
    "    df_jobs[salary_max_col] = pd.to_numeric(df_jobs[salary_max_col], errors='coerce')\n",
    "\n",
    "# Always create _row_avg_salary so later code won't fail\n",
    "def compute_row_avg(row):\n",
    "    a = row.get(salary_min_col) if salary_min_col in row.index else None\n",
    "    b = row.get(salary_max_col) if salary_max_col in row.index else None\n",
    "    if pd.notna(a) and pd.notna(b):\n",
    "        return (a + b) / 2.0\n",
    "    if pd.notna(a):\n",
    "        return a\n",
    "    if pd.notna(b):\n",
    "        return b\n",
    "    return None\n",
    "\n",
    "df_jobs[\"_row_avg_salary\"] = df_jobs.apply(compute_row_avg, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f90278ab-d287-448e-a269-2eceace6c603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- MERGE company info (to get company_name and country_code) ----------\n",
    "if company_id_col and 'dim_companies' in globals() and dim_companies is not None:\n",
    "    # Note: if dim_companies not available in CSV flow you can provide it similarly\n",
    "    df = df_jobs.merge(dim_companies, left_on=company_id_col, right_on='company_id', how='left', suffixes=(\"\",\"_comp\"))\n",
    "else:\n",
    "    # No dim_companies available: create placeholders\n",
    "    df = df_jobs.copy()\n",
    "    if 'company_name' not in df.columns:\n",
    "        df['company_name'] = df.get(company_id_col).astype(str) if company_id_col else \"UNKNOWN\"\n",
    "    if 'country_code' not in df.columns:\n",
    "        df['country_code'] = None\n",
    "\n",
    "# If country_code is null, mark as UNKNOWN\n",
    "df['country_code'] = df['country_code'].fillna(\"UNKNOWN\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6f31cbe5-a0bc-43e5-b8da-12df4ac91ff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved word cloud to: ./output\\wordcloud_skills.png\n"
     ]
    }
   ],
   "source": [
    "# ---------- 1) Word cloud: core skills from job_title + description ----------\n",
    "# Combine text\n",
    "text_columns = []\n",
    "if job_title_col:\n",
    "    text_columns.append(job_title_col)\n",
    "if desc_col:\n",
    "    text_columns.append(desc_col)\n",
    "if not text_columns:\n",
    "    # fallback to all string/object columns\n",
    "    text_columns = [c for c in df.columns if df[c].dtype == object]\n",
    "df[\"_combined_text\"] = df[text_columns].fillna(\"\").agg(\" \".join, axis=1)\n",
    "\n",
    "# Build token frequency weighted toward SKILL_KEYWORDS\n",
    "token_counter = Counter()\n",
    "for txt in df[\"_combined_text\"].astype(str).str.lower():\n",
    "    # count keyword occurrences\n",
    "    for kw in SKILL_KEYWORDS:\n",
    "        if kw in txt:\n",
    "            token_counter[kw] += txt.count(kw) * 5  # weight keywords a bit higher\n",
    "\n",
    "    # fallback tokenization for other words\n",
    "    tokens = re.findall(r\"[a-zA-Z\\+\\#\\-]{2,}\", txt)\n",
    "    for t in tokens:\n",
    "        if t in SKILL_KEYWORDS:\n",
    "            continue\n",
    "        token_counter[t] += 1\n",
    "\n",
    "# reduce extremely common stopwords\n",
    "stopwords = set([\n",
    "    \"the\",\"and\",\"to\",\"of\",\"a\",\"in\",\"for\",\"with\",\"on\",\"is\",\"as\",\"are\",\"be\",\n",
    "    \"by\",\"an\",\"or\",\"from\",\n",
    "    \"experience\",\"years\",\"year\",\"work\",\"ability\",\"use\",\"using\",\"knowledge\",\n",
    "    \"skills\",\"role\",\"responsibilities\",\n",
    "    \"required\",\"preferred\",\"must\",\"will\",\"team\",\"based\",\"data\",\"engineer\",\n",
    "    \"engineers\",\"job\",\"jobs\"\n",
    "])\n",
    "for s in stopwords:\n",
    "    if s in token_counter:\n",
    "        del token_counter[s]\n",
    "\n",
    "# create wordcloud from the most common tokens\n",
    "if token_counter:\n",
    "    wordcloud_input = {k: v for k, v in token_counter.most_common(200)}\n",
    "    wc = WordCloud(width=1200, height=600, \n",
    "                   background_color=\"white\").generate_from_frequencies(wordcloud_input)\n",
    "    wc_path = os.path.join(OUTPUT_DIR, \"wordcloud_skills.png\")\n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.imshow(wc, interpolation='bilinear')\n",
    "    plt.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(wc_path)\n",
    "    plt.close()\n",
    "    print(\"Saved word cloud to:\", wc_path)\n",
    "else:\n",
    "    print(\"No textual data found to create word cloud.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d7e5b979-222e-4656-a516-e50597d66f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved country bar chart to: ./output\\country_counts_bar.png\n"
     ]
    }
   ],
   "source": [
    "# ---------- 2) Which country are most DATA engineers coming from? ----------\n",
    "country_counts = df['country_code'].value_counts().reset_index()\n",
    "country_counts.columns = ['country_code', 'count']\n",
    "country_counts.to_csv(os.path.join(OUTPUT_DIR, \"country_counts.csv\"), index=False)\n",
    "\n",
    "# bar chart (top 20)\n",
    "top_country_counts = country_counts.head(20)\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.bar(range(len(top_country_counts)), top_country_counts['count'])\n",
    "plt.xticks(range(len(top_country_counts)), top_country_counts['country_code'], rotation=45, ha='right')\n",
    "plt.title(\"Top countries by job listings\")\n",
    "plt.tight_layout()\n",
    "country_plot_path = os.path.join(OUTPUT_DIR, \"country_counts_bar.png\")\n",
    "plt.savefig(country_plot_path)\n",
    "plt.close()\n",
    "print(\"Saved country bar chart to:\", country_plot_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "646a135c-a01a-40c6-a707-76eaff8cf1c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Min-Max salary per job title to: ./output\\minmax_salary_by_job_title.csv\n"
     ]
    }
   ],
   "source": [
    "# ---------- 3) Minâ€“Max Salary of each job title ----------\n",
    "# We'll compute min of salary_min and max of salary_max per job_title\n",
    "job_title_col_safe = job_title_col if job_title_col else 'job_title'\n",
    "if job_title_col_safe not in df.columns:\n",
    "    # create fallback\n",
    "    df[job_title_col_safe] = \"UNKNOWN\"\n",
    "\n",
    "agg_minmax = df.groupby(job_title_col_safe).agg(\n",
    "    min_salary_min = pd.NamedAgg(column=salary_min_col if salary_min_col in df.columns else salary_min_col, aggfunc=lambda s: pd.to_numeric(s, errors='coerce').min()),\n",
    "    max_salary_max = pd.NamedAgg(column=salary_max_col if salary_max_col in df.columns else salary_max_col, aggfunc=lambda s: pd.to_numeric(s, errors='coerce').max()),\n",
    "    count = pd.NamedAgg(column=job_title_col_safe, aggfunc='count')\n",
    ").reset_index().sort_values(['min_salary_min','max_salary_max'], ascending=[True, False])\n",
    "\n",
    "# Clean column names if NaN\n",
    "agg_minmax['min_salary_min'] = agg_minmax['min_salary_min'].replace({pd.NA: None})\n",
    "agg_minmax['max_salary_max'] = agg_minmax['max_salary_max'].replace({pd.NA: None})\n",
    "\n",
    "agg_minmax.to_csv(os.path.join(OUTPUT_DIR, \"minmax_salary_by_job_title.csv\"), index=False)\n",
    "print(\"Saved Min-Max salary per job title to:\", os.path.join(OUTPUT_DIR, \"minmax_salary_by_job_title.csv\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "56cbf1ec-beb5-41b2-a726-5432200d42f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved companies average salary chart to: ./output\\top_companies_avg_salary.png\n"
     ]
    }
   ],
   "source": [
    "# ---------- 4) Which companies offer the highest average salaries? ----------\n",
    "# Use company_name where available, else company_id\n",
    "company_name_col = 'company_name' if 'company_name' in df.columns else company_id_col\n",
    "company_avg = df.groupby(company_name_col)['_row_avg_salary'].mean().reset_index().rename(columns={'_row_avg_salary':'avg_salary'})\n",
    "company_avg = company_avg.sort_values('avg_salary', ascending=False).reset_index(drop=True)\n",
    "company_avg.head(50).to_csv(os.path.join(OUTPUT_DIR, \"top_companies_by_avg_salary.csv\"), index=False)\n",
    "\n",
    "# plot top 20 companies\n",
    "top_companies = company_avg.head(20)\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.bar(range(len(top_companies)), top_companies['avg_salary'])\n",
    "plt.xticks(range(len(top_companies)), top_companies[company_name_col].astype(str), rotation=45, ha='right')\n",
    "plt.title(\"Top companies by average salary (row average)\")\n",
    "plt.tight_layout()\n",
    "companies_plot_path = os.path.join(OUTPUT_DIR, \"top_companies_avg_salary.png\")\n",
    "plt.savefig(companies_plot_path)\n",
    "plt.close()\n",
    "print(\"Saved companies average salary chart to:\", companies_plot_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d420a5a5-3d52-4b35-bbdb-64de6e21c9bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_32652\\3887688053.py:10: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
      "  plt.boxplot(data_to_plot, labels=top_countries_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved salary-by-country boxplot to: ./output\\salary_by_country_boxplot.png\n"
     ]
    }
   ],
   "source": [
    "# ---------- 5) How do job salaries vary across countries? (boxplot) ----------\n",
    "# Take top N countries by count to avoid overcrowding\n",
    "top_n = 10\n",
    "top_countries_list = country_counts.head(top_n)['country_code'].tolist()\n",
    "plot_df = df[df['country_code'].isin(top_countries_list) & pd.notna(df['_row_avg_salary'])]\n",
    "\n",
    "if not plot_df.empty:\n",
    "    data_to_plot = [plot_df.loc[plot_df['country_code']==c, '_row_avg_salary'].values for c in top_countries_list]\n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.boxplot(data_to_plot, labels=top_countries_list)\n",
    "    plt.title(\"Salary distribution (row avg) by country - top countries\")\n",
    "    plt.ylabel(\"Salary\")\n",
    "    plt.xlabel(\"Country\")\n",
    "    plt.tight_layout()\n",
    "    boxplot_path = os.path.join(OUTPUT_DIR, \"salary_by_country_boxplot.png\")\n",
    "    plt.savefig(boxplot_path)\n",
    "    plt.close()\n",
    "    print(\"Saved salary-by-country boxplot to:\", boxplot_path)\n",
    "else:\n",
    "    print(\"Not enough salary data by country to draw boxplot.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a3941ff8-2699-41e2-b9e9-acdc5e244c05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs written to: C:\\Users\\User\\TP DE\\output\n",
      "Files: ['country_counts.csv', 'country_counts_bar.png', 'est_travel_times_all_20251202T234439Z.csv', 'est_travel_times_all_20251202T234439Z.json', 'est_travel_times_all_20251202T234506Z.csv', 'est_travel_times_all_20251202T234506Z.json', 'est_travel_times_woodlands_20251202T234439Z.csv', 'est_travel_times_woodlands_20251202T234439Z.json', 'est_travel_times_woodlands_20251202T234506Z.csv', 'est_travel_times_woodlands_20251202T234506Z.json', 'minmax_salary_by_job_title.csv', 'salary_by_country_boxplot.png', 'top_companies_avg_salary.png', 'top_companies_by_avg_salary.csv', 'wordcloud_skills.png']\n"
     ]
    }
   ],
   "source": [
    "# ---------- SUMMARY ----------\n",
    "print(\"Outputs written to:\", os.path.abspath(OUTPUT_DIR))\n",
    "print(\"Files:\", os.listdir(OUTPUT_DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f873ae3-508e-4202-a5aa-8f63d49ffba6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
